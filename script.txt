docker compose up -d

 docker  ps

 docker exec -it [] bash

/opt/spark/bin/spark-shell

docker stop spark-master spark-worker-1 jupyter-pyspark kafka zookeeper

---- chạy file kafka_stream.py trong folder kafka_stream ----
docker exec -it big-data-engineering-airflow-scheduler-1 python -c "
import sys
sys.path.insert(0, '/opt/airflow/dags')
from kafka_stream import get_data
print(get_data())
"

---- chạy file spark_stream.py trong folder spark_stream ----
docker exec big-data-engineering-airflow-scheduler-1 python -c 
"import sys; 
sys.path.insert(0, '/opt/airflow/dags'); 
from kafka_stream import stream_data; 
stream_data()"

--- file chưa có trong container ---
Copy-Item -Path ".\spark_stream" -Destination ".\data\" -Recurse -Force

---- chạy file spark_stream.py trong folder spark_stream ----
docker exec --user root spark-master /opt/spark/bin/spark-submit --master local[2] --packages com.datastax.spark:spark-cassandra-connector_2.12:3.4.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 /opt/spark-data/spark_stream/spark_stream.py

--- connect tới cassandra trên termical ---
docker exec -it cassandra cqlsh

